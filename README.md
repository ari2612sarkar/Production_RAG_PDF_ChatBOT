ğŸš€ Production-Grade PDF RAG Chatbot with FastAPI, LangChain, FAISS & HuggingFace
This project is a modular, intelligent Retrieval-Augmented Generation (RAG) chatbot that can answer complex queries from one or more PDFs. Built for production-readiness, it integrates modern NLP tools like LangChain, Hugging Face Transformers, and FAISS with a clean FastAPI backend.

ğŸ§  Why This Project Stands Out
âœ… Robust and modular codebase

âœ… Uses modern LLMs (Mistral-7B via Hugging Face Hub)

âœ… Streamlined PDF-to-Answer pipeline with LangChain

âœ… Real-time API interface with file upload and query support

âœ… Easily extensible: agent routing, metadata filtering, summarization, memory

ğŸ§± Project Structure
graphql
Copy
Edit
pdf_rag_chatbot/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py            # FastAPI API endpoints
â”‚   â”œâ”€â”€ rag.py             # Retrieval chain + agents
â”‚   â”œâ”€â”€ model.py           # LLM loader
â”‚   â”œâ”€â”€ loaders.py         # PDF parsing & text chunking
â”‚   â”œâ”€â”€ vector_store.py    # FAISS index management
â”‚   â”œâ”€â”€ tools.py           # QA + summarizer tools for agent
â”‚   â”œâ”€â”€ config.py          # Env vars and paths
â”‚   â”œâ”€â”€ utils.py           # Shared utilities
â”‚
â”œâ”€â”€ vector_store/          # Saved FAISS index and chunks
â”œâ”€â”€ data/                  # User-uploaded PDFs
â”œâ”€â”€ .env                   # Hugging Face API token
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
ğŸŒŸ Key Features
ğŸ“„ Ask Anything From Your PDFs
Upload one or more PDFs

Text is chunked intelligently using LangChain

Top-k relevant chunks are retrieved via FAISS

Answer generated using Mistral-7B-Instruct (Hugging Face)

ğŸ§© Modular and Maintainable Design
LangChain handles document loading, chunking, embeddings, retrieval

Easy plug-and-play LLM support via model.py

VectorDB abstracted through LangChain's FAISS wrapper

FastAPI decouples upload/query endpoints

ğŸ§  Multi-Turn Chat Support
Add conversation memory to maintain context

Ideal for interviews, follow-ups, and exploratory Q&A

ğŸ—‚ï¸ Metadata-Aware Retrieval
Chunks tagged with document name, page number

Filter answers by source

Trace every answer back to where it came from

ğŸ¤– Smart Agent-Orchestrated Behavior
Use LangChain agents to decide whether to:

Answer a query

Summarize a PDF

Route to other tools

Tools are modular and extendable (e.g., QA, summarizer)

âš™ï¸ Setup Instructions
1. Clone and Install Dependencies
bash
Copy
Edit
git clone https://github.com/ari2612sarkar/Production_RAG_PDF_ChatBOT
cd Production_RAG_PDF_ChatBOT
pip install -r requirements.txt
2. Add Your HuggingFace Token
Create a .env file in the root:

ini
Copy
Edit
HUGGINGFACEHUB_API_TOKEN=your_token_here
3. Run the FastAPI Backend
bash
Copy
Edit
uvicorn app.main:app --reload
Or start the interactive frontend:

bash
Copy
Edit
streamlit run streamlit_app.py
ğŸš€ Try It Out
Upload PDF
POST /upload/
Form field: file (PDF file)

Ask a Question
POST /query/
Form field: q (your question)

ğŸ“¬ Example API Output
json
Copy
Edit
{
  "response": "Retrieval-Augmented Generation (RAG) is a technique that combines document retrieval with large language models...",
  "sources": [
    {"doc": "AI_Assignment.pdf", "page": 3},
    {"doc": "LangChain_Guide.pdf", "page": 7}
  ]
}
ğŸ“¦ Requirements
nginx
Copy
Edit
fastapi
uvicorn
langchain
sentence-transformers
faiss-cpu
transformers
huggingface_hub
PyMuPDF
nltk
python-dotenv

ğŸ§  Built For RMgX
This chatbot was developed as part of the RMgX AI Developer Assignment, with clean modularization, agent tooling, multi-level abstraction, and best practices in LLM-based application engineering.

