# ğŸš€ Production-Grade PDF RAG Chatbot  
### FastAPI | LangChain | FAISS | HuggingFace

This project is a modular, intelligent **Retrieval-Augmented Generation (RAG) chatbot** that can answer complex queries from one or more PDFs.  
Built for **production-readiness**, it integrates modern NLP tools like **LangChain**, **Hugging Face Transformers**, and **FAISS** with a clean **FastAPI backend**.

---

## ğŸ§  Why This Project Stands Out
- âœ… Robust and modular codebase  
- âœ… Uses modern LLMs (**Mistral-7B via Hugging Face Hub**)  
- âœ… Streamlined **PDF-to-Answer pipeline** with LangChain  
- âœ… Real-time **API interface** with file upload & query support  
- âœ… Easily extensible: agents, metadata filtering, summarization, memory  

---

## ğŸ§± Project Structure
```
pdf_rag_chatbot/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py            # FastAPI API endpoints
â”‚   â”œâ”€â”€ rag.py             # Retrieval chain + agents
â”‚   â”œâ”€â”€ model.py           # LLM loader
â”‚   â”œâ”€â”€ loaders.py         # PDF parsing & text chunking
â”‚   â”œâ”€â”€ vector_store.py    # FAISS index management
â”‚   â”œâ”€â”€ tools.py           # QA + summarizer tools for agent
â”‚   â”œâ”€â”€ config.py          # Env vars and paths
â”‚   â”œâ”€â”€ utils.py           # Shared utilities
â”‚
â”œâ”€â”€ vector_store/          # Saved FAISS index and chunks
â”œâ”€â”€ data/                  # User-uploaded PDFs
â”œâ”€â”€ .env                   # Hugging Face API token
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
```


---

## ğŸŒŸ Key Features

### ğŸ“„ Ask Anything From Your PDFs
- Upload one or more PDFs  
- Text is chunked intelligently using LangChain  
- Top-k relevant chunks retrieved via FAISS  
- Answers generated using **Mistral-7B-Instruct**  

### ğŸ§© Modular & Maintainable Design
- LangChain handles document loading, chunking, embeddings, retrieval  
- Plug-and-play LLMs via `model.py`  
- VectorDB abstracted through FAISS wrapper  
- FastAPI decouples upload/query endpoints  

### ğŸ§  Multi-Turn Chat Support
- Add **conversation memory** to maintain context  
- Ideal for interviews, follow-ups, exploratory Q&A  

### ğŸ—‚ï¸ Metadata-Aware Retrieval
- Chunks tagged with **document name + page number**  
- Filter answers by source  
- Full answer traceability  

### ğŸ¤– Smart Agent-Orchestrated Behavior
- LangChain Agents decide whether to:  
  - Answer a query  
  - Summarize a PDF  
  - Route to other tools  
- Modular tools extend easily (QA, summarizer, etc.)  

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone and Install
git clone https://github.com/ari2612sarkar/Production_RAG_PDF_ChatBOT
cd Production_RAG_PDF_ChatBOT
pip install -r requirements.txt

### 2ï¸âƒ£ Add Your HuggingFace Token
Create a .env file in the root:
HUGGINGFACEHUB_API_TOKEN=your_token_here

### 3ï¸âƒ£ Run the FastAPI Backend
uvicorn app.main:app --reload
Or start the interactive frontend:
streamlit run streamlit_app.py

### ğŸš€ Try It Out
Upload PDF
POST /upload/
Form field: file (PDF file)

### Ask a Question
POST /query/
Form field: q (your question)

### ğŸ“¬ Example API Output
json
```
{
  "response": "Retrieval-Augmented Generation (RAG) is a technique that combines document retrieval with large language models...",
  "sources": [
    {"doc": "AI_Assignment.pdf", "page": 3},
    {"doc": "LangChain_Guide.pdf", "page": 7}
  ]
}

```

### ğŸ“¦ Requirements

```
fastapi
uvicorn
langchain
sentence-transformers
faiss-cpu
transformers
huggingface_hub
PyMuPDF
nltk
python-dotenv
```
